{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAX8yg3fUyfP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77371aae-b4c1-47a0-a27f-e2f744cf52cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers, losses\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/Shareddrives/ML_final_team01')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "male_train_csv = pd.read_csv(\"male_train.csv\")\n",
        "directory = 'male-crop-train-png'\n",
        "file_dir = os.listdir(directory)\n",
        "random.shuffle(file_dir)\n",
        "file_dir = file_dir[:2000]\n",
        "y_train = np.zeros((len(file_dir), 4))\n",
        "X_train = np.zeros((len(file_dir), 216, 334, 3))\n",
        "for p in range(len(file_dir)):\n",
        "    img = cv2.imread(directory+\"/\"+file_dir[p])\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = img / 255\n",
        "    X_train[p] = np.reshape(img, (216, 334, 3))\n",
        "    row = male_train_csv.loc[male_train_csv['filename'] == 'cv-other-train/'+file_dir[p][:-3]+'mp3']\n",
        "    if row['age'].values[0] == 'teens' or row['age'].values[0] == 'twenties':\n",
        "        y_train[p][0] = 1\n",
        "    elif row['age'].values[0] == 'thirties' or row['age'].values[0] == 'fourties':\n",
        "        y_train[p][1] = 1\n",
        "    elif row['age'].values[0] == 'fifties' or row['age'].values[0] == 'sixties':\n",
        "        y_train[p][2] = 1\n",
        "    elif row['age'].values[0] == 'seventies' or row['age'].values[0] == 'eighties' or row['age'].values[0] == 'nineties':\n",
        "        y_train[p][3] = 1"
      ],
      "metadata": {
        "id": "85UVCFgW2glr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "# count the number of each labels\n",
        "count_label = [0, 0, 0, 0, 0, 0, 0]\n",
        "index_memo = [[], [], [],[] , [], [], []]\n",
        "for i in range(len(file_dir)):\n",
        "    #print(file_dir[i])\n",
        "    row = male_train_csv.loc[male_train_csv['filename'] == 'cv-other-train/'+file_dir[i][:-3]+'mp3']\n",
        "    # print(row['age'].values[0])\n",
        "    if row['age'].values[0] == 'teens':\n",
        "        count_label[0] += 1\n",
        "        index_memo[0].append(i)\n",
        "    elif row['age'].values[0] == 'twenties':\n",
        "        count_label[1] += 1\n",
        "        index_memo[1].append(i)\n",
        "    elif row['age'].values[0] == 'thirties':\n",
        "        count_label[2] += 1\n",
        "        index_memo[2].append(i)\n",
        "    elif row['age'].values[0] == 'fourties':\n",
        "        count_label[3] += 1\n",
        "        index_memo[3].append(i)\n",
        "    elif row['age'].values[0] == 'fifties':\n",
        "        count_label[4] += 1\n",
        "        index_memo[4].append(i)\n",
        "    elif row['age'].values[0] == 'sixties':\n",
        "        count_label[5] += 1\n",
        "        index_memo[5].append(i)\n",
        "    elif row['age'].values[0] == 'seventies' or row['age'].values[0] == 'eighties' or row['age'].values[0] == 'nineties':\n",
        "        count_label[6] += 1\n",
        "        index_memo[6].append(i)\n",
        "print(count_label)\n",
        "'''"
      ],
      "metadata": {
        "id": "-2g6E4Egirva",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "2faf53d5-9730-4539-acf9-491ade4b4955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# count the number of each labels\\ncount_label = [0, 0, 0, 0, 0, 0, 0]\\nindex_memo = [[], [], [],[] , [], [], []]\\nfor i in range(len(file_dir)):\\n    #print(file_dir[i])\\n    row = male_train_csv.loc[male_train_csv['filename'] == 'cv-other-train/'+file_dir[i][:-3]+'mp3']\\n    # print(row['age'].values[0])\\n    if row['age'].values[0] == 'teens':\\n        count_label[0] += 1\\n        index_memo[0].append(i)\\n    elif row['age'].values[0] == 'twenties':\\n        count_label[1] += 1\\n        index_memo[1].append(i)\\n    elif row['age'].values[0] == 'thirties':\\n        count_label[2] += 1\\n        index_memo[2].append(i)\\n    elif row['age'].values[0] == 'fourties':\\n        count_label[3] += 1\\n        index_memo[3].append(i)\\n    elif row['age'].values[0] == 'fifties':\\n        count_label[4] += 1\\n        index_memo[4].append(i)\\n    elif row['age'].values[0] == 'sixties':\\n        count_label[5] += 1\\n        index_memo[5].append(i)\\n    elif row['age'].values[0] == 'seventies' or row['age'].values[0] == 'eighties' or row['age'].values[0] == 'nineties':\\n        count_label[6] += 1\\n        index_memo[6].append(i)\\nprint(count_label)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# convert label to one-hot encoded\n",
        "y_train = np.zeros((max(count_label) * 7, 7))\n",
        "# balance the data of different labels.\n",
        "X_train = np.array([])\n",
        "X_train = np.zeros((max(count_label) * 7, 216, 334, 3))\n",
        "duplicate_time = [math.floor(max(count_label)/ i) for i in count_label ]\n",
        "print(duplicate_time)\n",
        "file_count = 0\n",
        "p = 0\n",
        "while p < max(count_label) * 7 and file_count < 1000:\n",
        "    print(file_count)\n",
        "    img = cv2.imread(directory+\"/\"+file_dir[file_count])\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = img / 255\n",
        "    if file_count in index_memo[0]:\n",
        "        print('in [0]')\n",
        "        file_count = file_count + 1\n",
        "        for j in range(duplicate_time[0]):\n",
        "            X_train[p] = np.reshape(img, (216, 334, 3))\n",
        "            y_train[p][0] = 1\n",
        "            p = p + 1\n",
        "    elif file_count in index_memo[1]:\n",
        "        print('in [1]')\n",
        "        file_count = file_count + 1\n",
        "        for j in range(duplicate_time[1]):\n",
        "            X_train[p] = np.reshape(img, (216, 334, 3))\n",
        "            y_train[p][1] = 1\n",
        "            p = p + 1\n",
        "    elif file_count in index_memo[2]:\n",
        "        print('in [2]')\n",
        "        file_count = file_count + 1\n",
        "        for j in range(duplicate_time[2]):\n",
        "            X_train[p] = np.reshape(img, (216, 334, 3))\n",
        "            y_train[p][2] = 1\n",
        "            p = p + 1\n",
        "    elif file_count in index_memo[3]:\n",
        "        print('in [3]')\n",
        "        file_count = file_count + 1\n",
        "        for j in range(duplicate_time[3]):\n",
        "            X_train[p] = np.reshape(img, (216, 334, 3))\n",
        "            y_train[p][3] = 1\n",
        "            p = p + 1\n",
        "    elif file_count in index_memo[4]:\n",
        "        print('in [4]')\n",
        "        file_count = file_count + 1\n",
        "        for j in range(duplicate_time[4]):\n",
        "            X_train[p] = np.reshape(img, (216, 334, 3))\n",
        "            y_train[p][4] = 1            \n",
        "            p = p + 1\n",
        "    elif file_count in index_memo[5]:\n",
        "        print('in [5]')\n",
        "        file_count = file_count + 1\n",
        "        for j in range(duplicate_time[5]):\n",
        "            X_train[p] = np.reshape(img, (216, 334, 3))\n",
        "            y_train[p][5] = 1\n",
        "            p = p + 1\n",
        "    elif file_count in index_memo[6]:\n",
        "        print('in [6]')\n",
        "        file_count = file_count + 1\n",
        "        for j in range(duplicate_time[6]):\n",
        "            X_train[p] = np.reshape(img, (216, 334, 3))\n",
        "            y_train[p][6] = 1\n",
        "            p = p + 1\n",
        "'''"
      ],
      "metadata": {
        "id": "PWq0TapWVksy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "dd106a74-6972-4be4-d550-495d664c1000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# convert label to one-hot encoded\\ny_train = np.zeros((max(count_label) * 7, 7))\\n# balance the data of different labels.\\nX_train = np.array([])\\nX_train = np.zeros((max(count_label) * 7, 216, 334, 3))\\nduplicate_time = [math.floor(max(count_label)/ i) for i in count_label ]\\nprint(duplicate_time)\\nfile_count = 0\\np = 0\\nwhile p < max(count_label) * 7 and file_count < 1000:\\n    print(file_count)\\n    img = cv2.imread(directory+\"/\"+file_dir[file_count])\\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\\n    img = img / 255\\n    if file_count in index_memo[0]:\\n        print(\\'in [0]\\')\\n        file_count = file_count + 1\\n        for j in range(duplicate_time[0]):\\n            X_train[p] = np.reshape(img, (216, 334, 3))\\n            y_train[p][0] = 1\\n            p = p + 1\\n    elif file_count in index_memo[1]:\\n        print(\\'in [1]\\')\\n        file_count = file_count + 1\\n        for j in range(duplicate_time[1]):\\n            X_train[p] = np.reshape(img, (216, 334, 3))\\n            y_train[p][1] = 1\\n            p = p + 1\\n    elif file_count in index_memo[2]:\\n        print(\\'in [2]\\')\\n        file_count = file_count + 1\\n        for j in range(duplicate_time[2]):\\n            X_train[p] = np.reshape(img, (216, 334, 3))\\n            y_train[p][2] = 1\\n            p = p + 1\\n    elif file_count in index_memo[3]:\\n        print(\\'in [3]\\')\\n        file_count = file_count + 1\\n        for j in range(duplicate_time[3]):\\n            X_train[p] = np.reshape(img, (216, 334, 3))\\n            y_train[p][3] = 1\\n            p = p + 1\\n    elif file_count in index_memo[4]:\\n        print(\\'in [4]\\')\\n        file_count = file_count + 1\\n        for j in range(duplicate_time[4]):\\n            X_train[p] = np.reshape(img, (216, 334, 3))\\n            y_train[p][4] = 1            \\n            p = p + 1\\n    elif file_count in index_memo[5]:\\n        print(\\'in [5]\\')\\n        file_count = file_count + 1\\n        for j in range(duplicate_time[5]):\\n            X_train[p] = np.reshape(img, (216, 334, 3))\\n            y_train[p][5] = 1\\n            p = p + 1\\n    elif file_count in index_memo[6]:\\n        print(\\'in [6]\\')\\n        file_count = file_count + 1\\n        for j in range(duplicate_time[6]):\\n            X_train[p] = np.reshape(img, (216, 334, 3))\\n            y_train[p][6] = 1\\n            p = p + 1\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# get validation data\n",
        "directory = 'male-crop-test-png'\n",
        "file_dir = os.listdir(directory)\n",
        "random.shuffle(file_dir)\n",
        "file_dir = file_dir[:300]\n",
        "#print(file_dir)\n",
        "X_test = np.array([])\n",
        "X_test = np.zeros((len(file_dir), 216, 334, 3))\n",
        "for p in range(len(file_dir)):\n",
        "    img = cv2.imread(directory+\"/\"+file_dir[p])\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = img / 255\n",
        "    X_test[p] = np.reshape(img, (216, 334, 3))\n"
      ],
      "metadata": {
        "id": "Q80kEhyIgCf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "male_test_csv = pd.read_csv(\"male_test.csv\")\n",
        "# convert label to one-hot encoded\n",
        "y_test = np.zeros((len(file_dir), 4))\n",
        "for i in range(len(file_dir)):\n",
        "    #print(file_dir[i])\n",
        "    row = male_test_csv.loc[male_test_csv['filename'] == 'cv-other-test/'+file_dir[i][:-3]+'mp3']\n",
        "    # print(row['age'].values[0])\n",
        "    if row['age'].values[0] == 'teens' or row['age'].values[0] == 'twenties':\n",
        "        y_test[i][0] = 1\n",
        "    elif row['age'].values[0] == 'thirties' or row['age'].values[0] == 'fourties':\n",
        "        y_test[i][1] = 1\n",
        "    elif row['age'].values[0] == 'fifties' or row['age'].values[0] == 'sixties':\n",
        "        y_test[i][2] = 1\n",
        "    elif row['age'].values[0] == 'seventies' or row['age'].values[0] == 'eighties' or row['age'].values[0] == 'nineties':\n",
        "        y_test[i][3] = 1\n",
        "print(y_test)"
      ],
      "metadata": {
        "id": "S8sTmI-zngh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c4f7c6-8874-4689-b19d-19a122e75402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.RandomFlip(\"horizontal\"))\n",
        "model.add(layers.Conv2D(32, (4, 4), strides = 1, activation = 'relu', input_shape = (216, 334, 3)))\n",
        "model.add(layers.MaxPooling2D((4, 4), strides = 2))\n",
        "model.add(layers.Conv2D(32, (4, 4), activation='relu', strides = 2))\n",
        "model.add(layers.MaxPooling2D((4, 4), strides = 2))\n",
        "model.add(layers.Conv2D(64, (4, 4), activation='relu', strides = 2))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(4, activation='softmax'))\n",
        "#model.summary()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
        "History = model.fit(X_train, y_train, batch_size = 50, epochs = 13, validation_data = (X_test, y_test))"
      ],
      "metadata": {
        "id": "141-9BJXnzMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1fe7334-fddf-45b5-82ac-5661e78869f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "40/40 [==============================] - 13s 124ms/step - loss: 1.1316 - categorical_accuracy: 0.4220 - val_loss: 1.0552 - val_categorical_accuracy: 0.4000\n",
            "Epoch 2/15\n",
            "40/40 [==============================] - 4s 110ms/step - loss: 1.0839 - categorical_accuracy: 0.4275 - val_loss: 1.0819 - val_categorical_accuracy: 0.4000\n",
            "Epoch 3/15\n",
            "40/40 [==============================] - 4s 112ms/step - loss: 1.0863 - categorical_accuracy: 0.4285 - val_loss: 1.0494 - val_categorical_accuracy: 0.4833\n",
            "Epoch 4/15\n",
            "40/40 [==============================] - 5s 127ms/step - loss: 1.0764 - categorical_accuracy: 0.4475 - val_loss: 1.0433 - val_categorical_accuracy: 0.4700\n",
            "Epoch 5/15\n",
            "40/40 [==============================] - 4s 112ms/step - loss: 1.0698 - categorical_accuracy: 0.4735 - val_loss: 1.0351 - val_categorical_accuracy: 0.4733\n",
            "Epoch 6/15\n",
            "40/40 [==============================] - 5s 113ms/step - loss: 1.0498 - categorical_accuracy: 0.4695 - val_loss: 1.0196 - val_categorical_accuracy: 0.4500\n",
            "Epoch 7/15\n",
            "40/40 [==============================] - 4s 112ms/step - loss: 1.0178 - categorical_accuracy: 0.5030 - val_loss: 1.0240 - val_categorical_accuracy: 0.4567\n",
            "Epoch 8/15\n",
            "40/40 [==============================] - 5s 113ms/step - loss: 0.9902 - categorical_accuracy: 0.5080 - val_loss: 1.0155 - val_categorical_accuracy: 0.4900\n",
            "Epoch 9/15\n",
            "40/40 [==============================] - 5s 116ms/step - loss: 0.9572 - categorical_accuracy: 0.5490 - val_loss: 1.0378 - val_categorical_accuracy: 0.5000\n",
            "Epoch 10/15\n",
            "40/40 [==============================] - 4s 111ms/step - loss: 0.8818 - categorical_accuracy: 0.5905 - val_loss: 0.9942 - val_categorical_accuracy: 0.5100\n",
            "Epoch 11/15\n",
            "40/40 [==============================] - 5s 114ms/step - loss: 0.8273 - categorical_accuracy: 0.6240 - val_loss: 1.0386 - val_categorical_accuracy: 0.4633\n",
            "Epoch 12/15\n",
            "40/40 [==============================] - 5s 113ms/step - loss: 0.7482 - categorical_accuracy: 0.6705 - val_loss: 1.0777 - val_categorical_accuracy: 0.5333\n",
            "Epoch 13/15\n",
            "40/40 [==============================] - 5s 114ms/step - loss: 0.6452 - categorical_accuracy: 0.7275 - val_loss: 1.2978 - val_categorical_accuracy: 0.4800\n",
            "Epoch 14/15\n",
            "40/40 [==============================] - 4s 112ms/step - loss: 0.5395 - categorical_accuracy: 0.7890 - val_loss: 1.3178 - val_categorical_accuracy: 0.4700\n",
            "Epoch 15/15\n",
            "40/40 [==============================] - 4s 112ms/step - loss: 0.4155 - categorical_accuracy: 0.8335 - val_loss: 1.3554 - val_categorical_accuracy: 0.4833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save('male-age-pred')\n",
        "pred = model.predict_proba(X_test[2].reshape(1, 216, 334, 3))\n",
        "pred"
      ],
      "metadata": {
        "id": "PkPn3G5pVLKO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adc0ed25-7a10-425a-ec2d-798d4fdf4910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b79d19dbb03f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model.save('male-age-pred')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m216\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m334\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "age = ['0~30 years old', '30~50 years old', '50~70 years old', 'older than seventies']\n",
        "outcome = (-pred[0]).argsort()[:2]\n",
        "print(round(pred[0][outcome[0]] * 100, 1), \"% from\", age[outcome[0]])\n",
        "print(round(pred[0][outcome[1]] * 100, 1), \"% from\", age[outcome[1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIMnr_T_BIIH",
        "outputId": "dbae994f-54c4-4736-9d3c-3cfac7242e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81.4 % from 0~30 years old\n",
            "16.8 % from 30~50 years old\n"
          ]
        }
      ]
    }
  ]
}